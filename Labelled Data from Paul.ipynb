{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294593df",
   "metadata": {},
   "source": [
    "# Energy Disaggregation using Random Forest Regression\n",
    "recorded_data.csv contains the recorded activities that was given by Paul in a building along with the corresponding time and date information. Each row corresponds to a different activity. The data_30_minutes.csv contains the energy consumption data for pauls house, measured every 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4aa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from nilmtk.legacy.disaggregate import fhmm_exact\n",
    "from nilmtk import MeterGroup, ElecMeter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fhmm_model as fhmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061c8540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date      time          datetime         Activity\n",
      "0    12/01/2023  19:30:00  12/01/2023 19:30             Bath\n",
      "1    12/01/2023  19:28:00  12/01/2023 19:28       Dishwasher\n",
      "2    12/01/2023  19:40:00  12/01/2023 19:40  Washing Machine\n",
      "3    13/01/2023  06:55:00  13/01/2023 06:55           Kettle\n",
      "4    13/01/2023  07:30:00  13/01/2023 07:30           Kettle\n",
      "..          ...       ...               ...              ...\n",
      "236  02/02/2023  16:27:00  02/02/2023 16:27           Kettle\n",
      "237  02/02/2023  16:55:00  02/02/2023 16:55           Kettle\n",
      "238  02/02/2023  20:55:00  02/02/2023 20:55           Kettle\n",
      "239  03/02/2023  13:41:00  03/02/2023 13:41           Kettle\n",
      "240  03/02/2023  16:05:00  03/02/2023 16:05           Kettle\n",
      "\n",
      "[241 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"recorded_data.csv\")\n",
    "df_data = pd.read_csv(\"data_30_minutes.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a660256",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "While sorting through the dataframes, I realized that the appliance data needed to be organized specifically for the NILMTK toolkit. In order to achieve this, I created a vector data for each appliance, which would indicate the timescale that each appliance was in use. The process involved extracting unique values, creating activity value vectors, applying those vectors to the dataframe, sorting the dataframes by index, merging the two dataframes based on the 'datetime' column, interpolating any missing values using linear interpolation, and finally resetting the index of the resulting dataframe. The resulting cleaned data was then ready to be used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185b07dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date      time          datetime         Activity  \\\n",
      "0    12/01/2023  19:30:00  12/01/2023 19:30             Bath   \n",
      "1    12/01/2023  19:28:00  12/01/2023 19:28       Dishwasher   \n",
      "2    12/01/2023  19:40:00  12/01/2023 19:40  Washing Machine   \n",
      "3    13/01/2023  06:55:00  13/01/2023 06:55           Kettle   \n",
      "4    13/01/2023  07:30:00  13/01/2023 07:30           Kettle   \n",
      "..          ...       ...               ...              ...   \n",
      "236  02/02/2023  16:27:00  02/02/2023 16:27           Kettle   \n",
      "237  02/02/2023  16:55:00  02/02/2023 16:55           Kettle   \n",
      "238  02/02/2023  20:55:00  02/02/2023 20:55           Kettle   \n",
      "239  03/02/2023  13:41:00  03/02/2023 13:41           Kettle   \n",
      "240  03/02/2023  16:05:00  03/02/2023 16:05           Kettle   \n",
      "\n",
      "                                      Appliance_states  \n",
      "0    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "..                                                 ...  \n",
      "236  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "237  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "238  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "239  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "240  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "[241 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extracting the unique values\n",
    "appliances = df['Activity'].unique()\n",
    "# Creating the vectors for the activity values \n",
    "def create_appliance_vector(row, appliances):\n",
    "    appliance_states = []\n",
    "    for appliance in appliances:\n",
    "        if row['Activity'] == appliance:\n",
    "            appliance_states.append(1)\n",
    "        else:\n",
    "            appliance_states.append(0)\n",
    "    return appliance_states\n",
    "# Applying the vectors to the df \n",
    "df['Appliance_states'] = df.apply(lambda row: create_appliance_vector(row, appliances), axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7209ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date      time          datetime         Activity  \\\n",
      "0    12/01/2023  19:30:00  12/01/2023 19:30             Bath   \n",
      "1    12/01/2023  19:28:00  12/01/2023 19:28       Dishwasher   \n",
      "2    12/01/2023  19:40:00  12/01/2023 19:40  Washing Machine   \n",
      "3    13/01/2023  06:55:00  13/01/2023 06:55           Kettle   \n",
      "4    13/01/2023  07:30:00  13/01/2023 07:30           Kettle   \n",
      "..          ...       ...               ...              ...   \n",
      "236  02/02/2023  16:27:00  02/02/2023 16:27           Kettle   \n",
      "237  02/02/2023  16:55:00  02/02/2023 16:55           Kettle   \n",
      "238  02/02/2023  20:55:00  02/02/2023 20:55           Kettle   \n",
      "239  03/02/2023  13:41:00  03/02/2023 13:41           Kettle   \n",
      "240  03/02/2023  16:05:00  03/02/2023 16:05           Kettle   \n",
      "\n",
      "                                      Appliance_states  \n",
      "0    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "..                                                 ...  \n",
      "236  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "237  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "238  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "239  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "240  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "[241 rows x 5 columns]\n",
      "        Unnamed: 0                       tstp      energy\n",
      "0                0  2022-11-30 17:12:00+00:00  515.333333\n",
      "1                1  2022-11-30 17:16:00+00:00  228.590909\n",
      "2                2  2022-11-30 17:20:00+00:00  184.708333\n",
      "3                3  2022-11-30 17:24:00+00:00  349.040000\n",
      "4                4  2022-11-30 17:28:00+00:00  362.125000\n",
      "...            ...                        ...         ...\n",
      "927856     1685984  2023-02-12 20:26:48+00:00  370.204000\n",
      "927857     1685985  2023-02-12 20:31:48+00:00  371.433000\n",
      "927858     1685986  2023-02-12 20:36:48+00:00  372.583000\n",
      "927859     1685987  2023-02-12 20:41:48+00:00  373.614000\n",
      "927860     1685988  2023-02-12 20:46:48+00:00  374.367000\n",
      "\n",
      "[927861 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_appliance = df.sort_index()\n",
    "df_energy = df_data.sort_index()\n",
    "print(df_appliance)\n",
    "print(df_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d78bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date      time            datetime         Activity  \\\n",
      "136534  13/01/2023  06:55:00 2023-01-13 06:55:00           Kettle   \n",
      "136855  13/01/2023  07:30:00 2023-01-13 07:30:00           Kettle   \n",
      "137177  13/01/2023  08:05:00 2023-01-13 08:05:00    Office Heater   \n",
      "138043  13/01/2023  09:40:00 2023-01-13 09:40:00           Shower   \n",
      "138090  13/01/2023  09:45:00 2023-01-13 09:45:00           Kettle   \n",
      "...            ...       ...                 ...              ...   \n",
      "799699  03/02/2023  13:41:00 2023-03-02 13:41:00           Kettle   \n",
      "800582  03/02/2023  16:05:00 2023-03-02 16:05:00           Kettle   \n",
      "928089  12/01/2023  19:28:00 2023-12-01 19:28:00       Dishwasher   \n",
      "928090  12/01/2023  19:30:00 2023-12-01 19:30:00             Bath   \n",
      "928091  12/01/2023  19:40:00 2023-12-01 19:40:00  Washing Machine   \n",
      "\n",
      "                                         Appliance_states  Unnamed: 0  energy  \n",
      "136534  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     88683.5  3310.0  \n",
      "136855  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     88891.5   174.0  \n",
      "137177  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     89100.5   255.0  \n",
      "138043  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     89661.5   194.0  \n",
      "138090  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     89691.5   702.0  \n",
      "...                                                   ...         ...     ...  \n",
      "799699  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1009319.5  2747.0  \n",
      "800582  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1010116.5   379.5  \n",
      "928089  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1125700.0   202.0  \n",
      "928090  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1125700.0   202.0  \n",
      "928091  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1125700.0   202.0  \n",
      "\n",
      "[250 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_appliance['datetime'] = pd.to_datetime(df_appliance['datetime'])\n",
    "df_energy['tstp'] = pd.to_datetime(df_energy['tstp'])\n",
    "df_energy['tstp'] = df_energy['tstp'].dt.tz_convert(None)\n",
    "# Rename the 'tstp' column in df2 to 'datetime' for merging purposes\n",
    "df2 = df_energy.rename(columns={'tstp': 'datetime'})\n",
    "\n",
    "# Merge the two dataframes based on the 'datetime' column\n",
    "merged_df = pd.merge(df_appliance, df2, on='datetime', how='outer')\n",
    "\n",
    "# Sort the merged dataframe by 'datetime'\n",
    "merged_df = merged_df.sort_values(by='datetime')\n",
    "\n",
    "# Interpolate missing values using linear interpolation\n",
    "interpolated_df = merged_df.interpolate()\n",
    "\n",
    "# Reset the index of the final dataframe\n",
    "interpolated_df = interpolated_df.reset_index(drop=True)\n",
    "\n",
    "interpolated_df = interpolated_df[interpolated_df['Activity'].notna()]\n",
    "print(interpolated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff6773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe from values in Appliance states\n",
    "appliance_states_df = pd.DataFrame(interpolated_df['Appliance_states'].tolist(), index=interpolated_df.index)\n",
    "#to rename the columns with appliance names, need to do it well for the actual names\n",
    "appliance_states_df.columns = [f'appliance_{i+1}' for i in range(len(appliance_states_df.columns))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8304e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.concat([interpolated_df, appliance_states_df], axis=1)\n",
    "df_cleaned.drop('Appliance_states', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f02f37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date      time            datetime         Activity  Unnamed: 0  \\\n",
      "136534  13/01/2023  06:55:00 2023-01-13 06:55:00           Kettle     88683.5   \n",
      "136855  13/01/2023  07:30:00 2023-01-13 07:30:00           Kettle     88891.5   \n",
      "137177  13/01/2023  08:05:00 2023-01-13 08:05:00    Office Heater     89100.5   \n",
      "138043  13/01/2023  09:40:00 2023-01-13 09:40:00           Shower     89661.5   \n",
      "138090  13/01/2023  09:45:00 2023-01-13 09:45:00           Kettle     89691.5   \n",
      "...            ...       ...                 ...              ...         ...   \n",
      "799699  03/02/2023  13:41:00 2023-03-02 13:41:00           Kettle   1009319.5   \n",
      "800582  03/02/2023  16:05:00 2023-03-02 16:05:00           Kettle   1010116.5   \n",
      "928089  12/01/2023  19:28:00 2023-12-01 19:28:00       Dishwasher   1125700.0   \n",
      "928090  12/01/2023  19:30:00 2023-12-01 19:30:00             Bath   1125700.0   \n",
      "928091  12/01/2023  19:40:00 2023-12-01 19:40:00  Washing Machine   1125700.0   \n",
      "\n",
      "        energy  appliance_1  appliance_2  appliance_3  appliance_4  ...  \\\n",
      "136534  3310.0            0            0            0            1  ...   \n",
      "136855   174.0            0            0            0            1  ...   \n",
      "137177   255.0            0            0            0            0  ...   \n",
      "138043   194.0            0            0            0            0  ...   \n",
      "138090   702.0            0            0            0            1  ...   \n",
      "...        ...          ...          ...          ...          ...  ...   \n",
      "799699  2747.0            0            0            0            1  ...   \n",
      "800582   379.5            0            0            0            1  ...   \n",
      "928089   202.0            0            1            0            0  ...   \n",
      "928090   202.0            1            0            0            0  ...   \n",
      "928091   202.0            0            0            1            0  ...   \n",
      "\n",
      "        appliance_8  appliance_9  appliance_10  appliance_11  appliance_12  \\\n",
      "136534            0            0             0             0             0   \n",
      "136855            0            0             0             0             0   \n",
      "137177            0            0             0             0             0   \n",
      "138043            0            0             0             0             0   \n",
      "138090            0            0             0             0             0   \n",
      "...             ...          ...           ...           ...           ...   \n",
      "799699            0            0             0             0             0   \n",
      "800582            0            0             0             0             0   \n",
      "928089            0            0             0             0             0   \n",
      "928090            0            0             0             0             0   \n",
      "928091            0            0             0             0             0   \n",
      "\n",
      "        appliance_13  appliance_14  appliance_15  appliance_16  appliance_17  \n",
      "136534             0             0             0             0             0  \n",
      "136855             0             0             0             0             0  \n",
      "137177             0             0             0             0             0  \n",
      "138043             0             0             0             0             0  \n",
      "138090             0             0             0             0             0  \n",
      "...              ...           ...           ...           ...           ...  \n",
      "799699             0             0             0             0             0  \n",
      "800582             0             0             0             0             0  \n",
      "928089             0             0             0             0             0  \n",
      "928090             0             0             0             0             0  \n",
      "928091             0             0             0             0             0  \n",
      "\n",
      "[250 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef894c",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "The Random Forest Regressor model was created using scikit-learn library and was trained on the energy consumption dataset. The model was then used to make predictions on the validation set and the entire dataset. The Mean Squared Error (MSE) and Mean Absolute Error (MAE) were calculated to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4bc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature windows from the cleaned dataframe\n",
    "feature_windows = df_cleaned.iloc[:, -len(appliances):]\n",
    "\n",
    "# Extract the labels (energy consumption of each appliance) from the cleaned dataframe\n",
    "appliance_columns = [f'appliance_{i+1}' for i in range(len(appliances))]\n",
    "labels = df_cleaned[appliance_columns].values\n",
    "\n",
    "# Split the feature windows and labels into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_windows, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3036384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e07199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0017324705882352943\n",
      "Mean Absolute Error: 0.004141176470588236\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd00a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the entire dataset\n",
    "y_pred_all = model.predict(feature_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fae59c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy consumption of Bath: 5.20\n",
      "Energy consumption of Dishwasher: 9.05\n",
      "Energy consumption of Washing Machine: 6.00\n",
      "Energy consumption of Kettle: 126.00\n",
      "Energy consumption of Office Heater: 3.32\n",
      "Energy consumption of Shower: 21.00\n",
      "Energy consumption of Gas Hob: 34.00\n",
      "Energy consumption of Toaster: 9.03\n",
      "Energy consumption of Coffee Grinder: 14.00\n",
      "Energy consumption of Fan Oven: 2.58\n",
      "Energy consumption of Tumble Dryer: 6.06\n",
      "Energy consumption of Hoover: 1.15\n",
      "Energy consumption of Xmas Lights: 1.34\n",
      "Energy consumption of Oven: 5.87\n",
      "Energy consumption of Kitchen Heater: 4.13\n",
      "Energy consumption of Grill: 1.27\n",
      "Energy consumption of Heater: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the energy consumption for each appliance\n",
    "disaggregated_energy = y_pred_all.sum(axis=0)\n",
    "\n",
    "# Print the disaggregated energy for each appliance\n",
    "for i, energy in enumerate(disaggregated_energy):\n",
    "    print(f\"Energy consumption of {appliances[i]}: {energy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976933e",
   "metadata": {},
   "source": [
    "## Performance:\n",
    "The Model performance was interesting as the mean errors are low, However the predicted values of energy usage has some values which just look wrong due to the limited resources. This would include the limited amount of labelled data, the model used, and the preprocessing method to vectorise the Times that appliances are used as we do not have time period data for the length of time that the appliance is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d13a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
