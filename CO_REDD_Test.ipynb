{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8ebee4",
   "metadata": {},
   "source": [
    "# Energy Consumption Disaggregation REDD\n",
    "This uses the Combinatorial Optimization (CO) model, this takes the data preprocesses it into 1hr intervals, the CO model is trained on the combined training data and then tested for each house separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d578d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      " [train_on_chunk] Done training!\n",
      "Estimating power demand for 'Appliance1'\n",
      "Estimating power demand for 'Appliance2'\n",
      "Estimating power demand for 'Appliance3'\n",
      "Estimating power demand for 'Appliance4'\n",
      "Estimating power demand for 'Appliance5'\n",
      "Estimating power demand for 'Appliance6'\n",
      "Estimating power demand for 'Appliance7'\n",
      "Estimating power demand for 'Appliance8'\n",
      "Estimating power demand for 'Appliance9'\n",
      "Estimating power demand for 'Appliance1'\n",
      "Estimating power demand for 'Appliance2'\n",
      "Estimating power demand for 'Appliance3'\n",
      "Estimating power demand for 'Appliance4'\n",
      "Estimating power demand for 'Appliance5'\n",
      "Estimating power demand for 'Appliance6'\n",
      "Estimating power demand for 'Appliance7'\n",
      "Estimating power demand for 'Appliance8'\n",
      "Estimating power demand for 'Appliance9'\n",
      "Estimating power demand for 'Appliance1'\n",
      "Estimating power demand for 'Appliance2'\n",
      "Estimating power demand for 'Appliance3'\n",
      "Estimating power demand for 'Appliance4'\n",
      "Estimating power demand for 'Appliance5'\n",
      "Estimating power demand for 'Appliance6'\n",
      "Estimating power demand for 'Appliance7'\n",
      "Estimating power demand for 'Appliance8'\n",
      "Estimating power demand for 'Appliance9'\n",
      "                     Appliance1  Appliance2  Appliance3  Appliance4  \\\n",
      "timestamp                                                             \n",
      "2015-01-31 18:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:50:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-07-10 11:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:50:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance5  Appliance6  Appliance7  Appliance8  \\\n",
      "timestamp                                                             \n",
      "2015-01-31 18:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-01-31 18:50:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-07-10 11:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-07-10 11:50:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance9  \n",
      "timestamp                        \n",
      "2015-01-31 18:10:00         0.0  \n",
      "2015-01-31 18:20:00         0.0  \n",
      "2015-01-31 18:30:00         0.0  \n",
      "2015-01-31 18:40:00         0.0  \n",
      "2015-01-31 18:50:00         0.0  \n",
      "...                         ...  \n",
      "2015-07-10 11:10:00         0.0  \n",
      "2015-07-10 11:20:00         0.0  \n",
      "2015-07-10 11:30:00         0.0  \n",
      "2015-07-10 11:40:00         0.0  \n",
      "2015-07-10 11:50:00         0.0  \n",
      "\n",
      "[23003 rows x 9 columns]\n",
      "                     Appliance1  Appliance2  Appliance3  Appliance4  \\\n",
      "timestamp                                                             \n",
      "2014-12-24 23:30:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-24 23:40:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-24 23:50:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-25 00:00:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-25 00:10:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-05-28 07:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:50:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 08:00:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance5  Appliance6  Appliance7  Appliance8  \\\n",
      "timestamp                                                             \n",
      "2014-12-24 23:30:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-24 23:40:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-24 23:50:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-25 00:00:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-25 00:10:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-05-28 07:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 07:50:00         0.0         0.0         0.0         0.0   \n",
      "2015-05-28 08:00:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance9  \n",
      "timestamp                        \n",
      "2014-12-24 23:30:00         0.0  \n",
      "2014-12-24 23:40:00         0.0  \n",
      "2014-12-24 23:50:00         0.0  \n",
      "2014-12-25 00:00:00         0.0  \n",
      "2014-12-25 00:10:00         0.0  \n",
      "...                         ...  \n",
      "2015-05-28 07:20:00         0.0  \n",
      "2015-05-28 07:30:00         0.0  \n",
      "2015-05-28 07:40:00         0.0  \n",
      "2015-05-28 07:50:00         0.0  \n",
      "2015-05-28 08:00:00         0.0  \n",
      "\n",
      "[22228 rows x 9 columns]\n",
      "                     Appliance1  Appliance2  Appliance3  Appliance4  \\\n",
      "timestamp                                                             \n",
      "2014-12-30 19:00:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:10:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:20:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:30:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:40:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-06-02 10:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:50:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance5  Appliance6  Appliance7  Appliance8  \\\n",
      "timestamp                                                             \n",
      "2014-12-30 19:00:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:10:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:20:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:30:00         0.0         0.0         0.0         0.0   \n",
      "2014-12-30 19:40:00         0.0         0.0         0.0         0.0   \n",
      "...                         ...         ...         ...         ...   \n",
      "2015-06-02 10:10:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:20:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:30:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:40:00         0.0         0.0         0.0         0.0   \n",
      "2015-06-02 10:50:00         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                     Appliance9  \n",
      "timestamp                        \n",
      "2014-12-30 19:00:00         0.0  \n",
      "2014-12-30 19:10:00         0.0  \n",
      "2014-12-30 19:20:00         0.0  \n",
      "2014-12-30 19:30:00         0.0  \n",
      "2014-12-30 19:40:00         0.0  \n",
      "...                         ...  \n",
      "2015-06-02 10:10:00         0.0  \n",
      "2015-06-02 10:20:00         0.0  \n",
      "2015-06-02 10:30:00         0.0  \n",
      "2015-06-02 10:40:00         0.0  \n",
      "2015-06-02 10:50:00         0.0  \n",
      "\n",
      "[22128 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import co_model as co\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('REDD/CLEAN_House1.csv')\n",
    "df1 = pd.read_csv('REDD/CLEAN_House2.csv')\n",
    "df2 = pd.read_csv('REDD/CLEAN_House3.csv')\n",
    "\n",
    "# Function to process each DataFrame\n",
    "def process_dataframe(df):\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df.set_index('Time', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Process all DataFrames\n",
    "dfs = [df, df1, df2,]\n",
    "dfs = [process_dataframe(df) for df in dfs]\n",
    "\n",
    "\n",
    "# Resample the data to hourly intervals and sum the power consumption for each hour\n",
    "df_hourly = df.resample('10T').sum()\n",
    "df1_hourly = df1.resample('10T').sum()\n",
    "df2_hourly = df2.resample('10T').sum()\n",
    "# Calculate the hourly consumption for each appliance in Wh\n",
    "for i in range(1, 10):\n",
    "    df_hourly[f'Appliance{i} (Wh)'] = df_hourly[f'Appliance{i}'] * 1000\n",
    "    df1_hourly[f'Appliance{i} (Wh)'] = df1_hourly[f'Appliance{i}'] * 1000\n",
    "    df2_hourly[f'Appliance{i} (Wh)'] = df2_hourly[f'Appliance{i}'] * 1000\n",
    "# Convert the hourly consumption for each appliance to kWh\n",
    "df_hourly = df_hourly.div(1000000)\n",
    "df1_hourly = df1_hourly.div(1000000)\n",
    "df2_hourly = df2_hourly.div(1000000)\n",
    "\n",
    "split_index = int(len(df_hourly) * 0.75)\n",
    "train_df = df_hourly.iloc[:split_index]\n",
    "test_df = df_hourly.iloc[split_index:]\n",
    "\n",
    "split_index = int(len(df1_hourly) * 0.75)\n",
    "train_df1 = df1_hourly.iloc[:split_index]\n",
    "test_df1 = df1_hourly.iloc[split_index:]\n",
    "\n",
    "split_index = int(len(df2_hourly) * 0.75)\n",
    "train_df2 = df2_hourly.iloc[:split_index]\n",
    "test_df2 = df2_hourly.iloc[split_index:]\n",
    "\n",
    "train_df = train_df.reset_index()\n",
    "train_df['timestamp'] = (pd.to_datetime(train_df['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "train_df = train_df[['timestamp', 'Aggregate'] + [f'Appliance{i}' for i in range(1, 10)]]\n",
    "train_df = train_df.rename(columns={'Aggregate': 'power'})\n",
    "\n",
    "train_df1 = train_df1.reset_index()\n",
    "train_df1['timestamp'] = (pd.to_datetime(train_df1['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "train_df1 = train_df1[['timestamp', 'Aggregate'] + [f'Appliance{i}' for i in range(1, 10)]]\n",
    "train_df1 = train_df1.rename(columns={'Aggregate': 'power'})\n",
    "\n",
    "train_df2 = train_df2.reset_index()\n",
    "train_df2['timestamp'] = (pd.to_datetime(train_df2['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "train_df2 = train_df2[['timestamp', 'Aggregate'] + [f'Appliance{i}' for i in range(1, 10)]]\n",
    "train_df2 = train_df2.rename(columns={'Aggregate': 'power'})\n",
    "\n",
    "test_df = test_df.reset_index()\n",
    "test_df['timestamp'] = (pd.to_datetime(test_df['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "test_df = test_df.rename(columns={'Aggregate': 'power'})\n",
    "\n",
    "test_df1 = test_df1.reset_index()\n",
    "test_df1['timestamp'] = (pd.to_datetime(test_df1['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "test_df1 = test_df1.rename(columns={'Aggregate': 'power'})\n",
    "\n",
    "test_df2 = test_df2.reset_index()\n",
    "test_df2['timestamp'] = (pd.to_datetime(test_df2['Time']).astype(np.int64) // 10**9).astype(int)\n",
    "test_df2 = test_df2.rename(columns={'Aggregate': 'power'})\n",
    "list_of_appliances = [f'Appliance{i}' for i in range(1, 10)]\n",
    "\n",
    "train_df = pd.concat([train_df, train_df1, train_df2])\n",
    "model = co.CO()\n",
    "model.train(train_df, list_of_appliances)\n",
    "\n",
    "model.save(\"co_trained_model_REDD.pkl\")\n",
    "\n",
    "prediction2 = model.disaggregate(test_df2)\n",
    "prediction1 = model.disaggregate(test_df1)\n",
    "prediction = model.disaggregate(test_df)\n",
    "print(prediction)\n",
    "print(prediction1)\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1365aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for test_df:\n",
      "   Appliance       MAE      RMSE  R2 Score\n",
      "0     Fridge  0.001281  0.003796 -0.128579\n",
      "1       Oven  0.001232  0.002151 -0.488803\n",
      "2     Washer  0.002122  0.003502 -0.579889\n",
      "3      Dryer  0.000052  0.002586 -0.000404\n",
      "4   Lighting  0.000978  0.010606 -0.008570\n",
      "5  Microwave  0.000822  0.010921 -0.005703\n",
      "6         TV  0.000279  0.001141 -0.063418\n",
      "7   Computer  0.000393  0.001060 -0.159588\n",
      "8     Others  0.006016  0.019899 -0.100581\n",
      "\n",
      "Evaluation results for test_df1:\n",
      "   Appliance       MAE      RMSE  R2 Score\n",
      "0     Fridge  0.002651  0.004339 -0.595357\n",
      "1       Oven  0.001566  0.013674 -0.013283\n",
      "2     Washer  0.006000  0.029976 -0.041742\n",
      "3      Dryer  0.000322  0.001062 -0.101507\n",
      "4   Lighting  0.000351  0.003362 -0.011036\n",
      "5  Microwave  0.000141  0.001872 -0.005722\n",
      "6         TV  0.000088  0.000355 -0.065208\n",
      "7   Computer  0.001767  0.009557 -0.035400\n",
      "8     Others  0.000056  0.000567 -0.009904\n",
      "\n",
      "Evaluation results for test_df2:\n",
      "   Appliance       MAE      RMSE  R2 Score\n",
      "0     Fridge  0.000161  0.002051 -0.006218\n",
      "1       Oven  0.003955  0.006168 -0.697977\n",
      "2     Washer  0.002477  0.004109 -0.570770\n",
      "3      Dryer  0.004495  0.025486 -0.032101\n",
      "4   Lighting  0.004192  0.025201 -0.028452\n",
      "5  Microwave  0.002437  0.015972 -0.023827\n",
      "6         TV  0.003648  0.006717 -0.418362\n",
      "7   Computer  0.000263  0.003085 -0.007345\n",
      "8     Others  0.001662  0.008526 -0.039478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Create a function to evaluate the model performance\n",
    "def evaluate_model(test_df, prediction_df, appliance_names):\n",
    "    evaluation_metrics = {'Appliance': [], 'MAE': [], 'RMSE': [], 'R2 Score': []}\n",
    "    for i in range(1, 10):\n",
    "        appliance = f'Appliance{i}'\n",
    "        true_values = test_df[appliance]\n",
    "        predicted_values = prediction_df[appliance]\n",
    "        \n",
    "        mae = mean_absolute_error(true_values, predicted_values)\n",
    "        rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "        r2 = r2_score(true_values, predicted_values)\n",
    "        \n",
    "        evaluation_metrics['Appliance'].append(appliance)\n",
    "        evaluation_metrics['MAE'].append(mae)\n",
    "        evaluation_metrics['RMSE'].append(rmse)\n",
    "        evaluation_metrics['R2 Score'].append(r2)\n",
    "    \n",
    "    return pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "appliance_names = {'Appliance1': 'Fridge', 'Appliance2': 'Oven', 'Appliance3': 'Washer', 'Appliance4': 'Dryer', 'Appliance5': 'Lighting', 'Appliance6': 'Microwave', 'Appliance7': 'TV', 'Appliance8': 'Computer', 'Appliance9': 'Others'}\n",
    "\n",
    "evaluation_results = evaluate_model(test_df, prediction, appliance_names)\n",
    "evaluation_results['Appliance'] = evaluation_results['Appliance'].map(appliance_names)\n",
    "\n",
    "evaluation_results1 = evaluate_model(test_df1, prediction1, appliance_names)\n",
    "evaluation_results1['Appliance'] = evaluation_results1['Appliance'].map(appliance_names)\n",
    "\n",
    "evaluation_results2 = evaluate_model(test_df2, prediction2, appliance_names)\n",
    "evaluation_results2['Appliance'] = evaluation_results2['Appliance'].map(appliance_names)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation results for test_df:\")\n",
    "print(evaluation_results)\n",
    "print(\"\\nEvaluation results for test_df1:\")\n",
    "print(evaluation_results1)\n",
    "print(\"\\nEvaluation results for test_df2:\")\n",
    "print(evaluation_results2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef9d96",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The evaluation results show the performance of the CO model for disaggregating energy consumption for each appliance in the three houses. Further improvements can be made by tuning the model hyperparameters or exploring other disaggregation techniques. At the current moment when I was finished working here I would prefer using the FHMM model compared. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
