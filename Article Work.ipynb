{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d5b7b3",
   "metadata": {},
   "source": [
    "# Article Work \n",
    "We looked at an article Chakraborty, P. (2021). Energy Management Using Real-Time Non-Intrusive Load Monitoring. [online] Towards Data Science. Available at: https://towardsdatascience.com/energy-management-using-real-time-non-intrusive-load-monitoring-3c9b0b4c8291 [Accessed 23 Apr. 2023]. In which we decided to try and follow the steps and methodolgy used using our Kaggle data as the dataset this is the attempt that was made on this method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3b0958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bf29650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3221: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        DateTime      LCLid         KWh Acorn  \\\n",
      "0      2011-12-06 15:30:00+00:00  MAC000017  127.000000     C   \n",
      "1      2011-12-06 15:40:00+00:00  MAC000017  109.666667     C   \n",
      "2      2011-12-06 15:50:00+00:00  MAC000017   92.333333     C   \n",
      "3      2011-12-06 16:00:00+00:00  MAC000017   75.000000     C   \n",
      "4      2011-12-06 16:10:00+00:00  MAC000017   70.666667     C   \n",
      "...                          ...        ...         ...   ...   \n",
      "117263 2014-02-27 23:20:00+00:00  MAC000323  816.666667     A   \n",
      "117264 2014-02-27 23:30:00+00:00  MAC000323  789.000000     A   \n",
      "117265 2014-02-27 23:40:00+00:00  MAC000323  637.333333     A   \n",
      "117266 2014-02-27 23:50:00+00:00  MAC000323  485.666667     A   \n",
      "117267 2014-02-28 00:00:00+00:00  MAC000323  334.000000     A   \n",
      "\n",
      "               House Type Amount of Beds House Value  \\\n",
      "0        Detached Houses               4    750k-1m    \n",
      "1        Detached Houses               4    750k-1m    \n",
      "2        Detached Houses               4    750k-1m    \n",
      "3        Detached Houses               4    750k-1m    \n",
      "4        Detached Houses               4    750k-1m    \n",
      "...                   ...            ...         ...   \n",
      "117263   Detached Houses             5+          1m+   \n",
      "117264   Detached Houses             5+          1m+   \n",
      "117265   Detached Houses             5+          1m+   \n",
      "117266   Detached Houses             5+          1m+   \n",
      "117267   Detached Houses             5+          1m+   \n",
      "\n",
      "       How many People Living there  \n",
      "0                                 2  \n",
      "1                                 2  \n",
      "2                                 2  \n",
      "3                                 2  \n",
      "4                                 2  \n",
      "...                             ...  \n",
      "117263                          5+   \n",
      "117264                          5+   \n",
      "117265                          5+   \n",
      "117266                          5+   \n",
      "117267                          5+   \n",
      "\n",
      "[117268 rows x 8 columns]\n",
      "['4' '5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricky\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '5']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert_suffix(value)\n\u001b[1;32m--> 109\u001b[0m df_resampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHouse Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHouse Value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_house_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Normalize the 'KWh' and 'House Value' columns\u001b[39;00m\n\u001b[0;32m    111\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nilmtk\\lib\\site-packages\\pandas\\core\\series.py:4045\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4043\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4044\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m-> 4045\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], Series):\n\u001b[0;32m   4048\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   4049\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   4050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd\u001b[38;5;241m.\u001b[39marray(mapped), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mpandas\\_libs\\lib.pyx:2228\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[18], line 102\u001b[0m, in \u001b[0;36mconvert_house_value\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(num_str)\n\u001b[1;32m--> 102\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[^\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdkm-]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Remove non-numeric characters except k and m\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[0;32m    104\u001b[0m     low, high \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nilmtk\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('London_House_data.csv', dtype=dtypes)\n",
    "\n",
    "# Remove spaces from column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Convert the DateTime column to pandas datetime objects\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "# Remove duplicates in the DateTime column\n",
    "df = df.drop_duplicates(subset='DateTime')\n",
    "\n",
    "# Set the DateTime column as the index\n",
    "df = df.set_index('DateTime')\n",
    "\n",
    "# Resample to 10-minute intervals and interpolate the KWh column\n",
    "df_resampled = df.resample('10T').interpolate(method='linear', limit_area='inside')\n",
    "\n",
    "# Forward fill the other columns\n",
    "df_resampled[['LCLid', 'Acorn', 'House Type', 'Amount of Beds', 'House Value', 'How many People Living there']] = df_resampled[['LCLid', 'Acorn', 'House Type', 'Amount of Beds', 'House Value', 'How many People Living there']].ffill()\n",
    "\n",
    "# Reset the index\n",
    "df_resampled = df_resampled.reset_index()\n",
    "print(df_resampled)\n",
    "# One-hot encode the 'Acorn' column\n",
    "acorn_encoder = OneHotEncoder(sparse=False)\n",
    "acorn_encoded = acorn_encoder.fit_transform(df_resampled['Acorn'].values.reshape(-1, 1))\n",
    "acorn_labels = acorn_encoder.categories_[0]\n",
    "# Convert 'Amount of Beds' values to strings\n",
    "df_resampled['Amount of Beds'] = df_resampled['Amount of Beds'].astype(str).str.strip()\n",
    "df_resampled['Amount of Beds'] = df_resampled['Amount of Beds'].replace('5+', '5')\n",
    "print(df_resampled['Amount of Beds'].unique())\n",
    "df_resampled['Amount of Beds'] = df_resampled['Amount of Beds'].astype(float)\n",
    "# Convert 'How many People Living there' values to strings\n",
    "df_resampled['How many People Living there'] = df_resampled['How many People Living there'].astype(str).str.strip()\n",
    "df_resampled['How many People Living there'] = df_resampled['How many People Living there'].replace('5+', '5')\n",
    "print(df_resampled['How many People Living there'].unique())\n",
    "df_resampled['How many People Living there'] = df_resampled['How many People Living there'].astype(float)\n",
    "def convert_house_value(value):\n",
    "    def convert_suffix(num_str):\n",
    "        num_str = num_str.lower()\n",
    "        if 'k' in num_str:\n",
    "            return float(num_str.replace('k', '')) * 1_000\n",
    "        elif 'm' in num_str:\n",
    "            return float(num_str.replace('m', '')) * 1_000_000\n",
    "        else:\n",
    "            return float(num_str)\n",
    "\n",
    "    if pd.isna(value) or value == 'nan' or value == '0':\n",
    "        return 0.0\n",
    "\n",
    "    value = str(value).strip()\n",
    "    value = re.sub('[^\\dkm-]', '', value)  # Remove non-numeric characters except k and m\n",
    "\n",
    "    if '-' in value:\n",
    "        low, high = value.split('-')\n",
    "        low = convert_suffix(low)\n",
    "        high = convert_suffix(high)\n",
    "        return (low + high) / 2\n",
    "    else:\n",
    "        return convert_suffix(value)\n",
    "\n",
    "# Convert House Value\n",
    "df_resampled['House Value'] = df_resampled['House Value'].astype(str)\n",
    "df_resampled['House Value'] = df_resampled['House Value'].apply(lambda x: convert_house_value(x) if x else 0)\n",
    "df_resampled['House Value'] = df_resampled['House Value'].astype(float)\n",
    "\n",
    "\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('100k-150k', '150000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('150k-200k', '200000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('200k-250k', '250000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('250k-300k', '300000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('300k-350k', '350000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('350k-400k', '400000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('400k-450k', '450000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('450k-500k', '500000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('500k-750k', '750000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('750k-1m', '1000000')\n",
    "df_resampled['House Value'] = df_resampled['House Value'].replace('1m+', '1005000')\n",
    "\n",
    "\n",
    "\n",
    "# Label encode the 'Amount of Beds' column\n",
    "beds_encoder = LabelEncoder()\n",
    "beds_encoded = beds_encoder.fit_transform(df_resampled['Amount of Beds'].values)\n",
    "beds_labels = beds_encoder.classes_\n",
    "\n",
    "# Label encode the 'Amount of Beds' column\n",
    "beds_encoder = LabelEncoder()\n",
    "beds_encoded = beds_encoder.fit_transform(df_resampled['Amount of Beds'].values)\n",
    "beds_labels = beds_encoder.classes_\n",
    "def convert_house_value(value):\n",
    "    def convert_suffix(num_str):\n",
    "        if 'k' in num_str:\n",
    "            return float(num_str.replace('k', '')) * 1e3\n",
    "        elif 'm' in num_str:\n",
    "            return float(num_str.replace('m', '')) * 1e6\n",
    "        else:\n",
    "            return float(num_str)\n",
    "\n",
    "    value = re.sub('[^\\dkm-]', '', value)  # Remove non-numeric characters except k and m\n",
    "    if '-' in value:\n",
    "        low, high = value.split('-')\n",
    "        return (convert_suffix(low) + convert_suffix(high)) / 2\n",
    "    else:\n",
    "        return convert_suffix(value)\n",
    "\n",
    "df_resampled['House Value'] = df_resampled['House Value'].apply(convert_house_value)\n",
    "# Normalize the 'KWh' and 'House Value' columns\n",
    "scaler = MinMaxScaler()\n",
    "df_resampled['KWh_normalized'] = scaler.fit_transform(df_resampled['KWh'].values.reshape(-1, 1))\n",
    "df_resampled['House Value_normalized'] = scaler.fit_transform(df_resampled['House Value'].values.reshape(-1, 1))\n",
    "\n",
    "# Add the encoded columns to the DataFrame\n",
    "df_encoded = pd.DataFrame(acorn_encoded, columns=[f'Acorn_{label}' for label in acorn_labels], index=df_resampled.index)\n",
    "df_encoded['Amount of Beds'] = beds_encoded\n",
    "df_encoded['House Value'] = df_resampled['House Value_normalized']\n",
    "df_encoded['How many People Living there'] = df_resampled['How many People Living there']\n",
    "\n",
    "# Generate input and target samples using a sliding window\n",
    "window_size = 6\n",
    "stride = 1\n",
    "inputs, targets = generate_samples(df_encoded.values, window_size, stride)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316183a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we use Skilearn instead then Decision Tree could be possible \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and test sets\n",
    "split = int(0.75 * len(inputs))\n",
    "train_inputs, test_inputs = inputs[:split], inputs[split:]\n",
    "train_targets, test_targets = targets[:split], targets[split:]\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(train_inputs, train_targets)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_inputs)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test_targets, predictions)\n",
    "print(f'MSE: {mse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f9989",
   "metadata": {},
   "source": [
    "## Failures:\n",
    "Trying my best to keep up with the article, I had two major issues, the first is that when preprocessing the data There was issues with string elements and my laptop refused to install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39322144",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the model architecture\n",
    "input_shape = (window_size, inputs.shape[2])\n",
    "input_layer = Input(shape=input_shape)\n",
    "conv1_layer = Conv1D(filters=16, kernel_size=3, activation='relu')(input_layer)\n",
    "pool1_layer = MaxPooling1D(pool_size=2)(conv1_layer)\n",
    "conv2_layer = Conv1D(filters=32, kernel_size=3, activation='relu')(pool1_layer)\n",
    "pool2_layer = MaxPooling1D(pool_size=2)(conv2_layer)\n",
    "flatten_layer = Flatten()(pool2_layer)\n",
    "dense1_layer = Dense(units=64, activation='relu')(flatten_layer)\n",
    "dropout_layer = Dropout(rate=0.5)(dense1_layer)\n",
    "output_layer = Dense(units=1)(dropout_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(inputs, targets, batch_size=64, epochs=50, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(inputs)\n",
    "mse = mean_squared_error(targets, predictions)\n",
    "print(f'MSE: {mse:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
